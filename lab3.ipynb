{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "ES3y9WlGlGdG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OvZaiUXom1Wm"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "from io import BytesIO\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import time\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from typing import Type\n",
        "from datetime import datetime\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import data"
      ],
      "metadata": {
        "id": "D_zq_0PrlIaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the dataset\n",
        "dataset_path = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'\n",
        "\n",
        "# Send a GET request to the URL\n",
        "response = requests.get(dataset_path)\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Open the downloaded bytes and extract them\n",
        "    with ZipFile(BytesIO(response.content)) as zip_file:\n",
        "        zip_file.extractall('/dataset')\n",
        "    print('Download and extraction complete!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJoh2EF_m9hh",
        "outputId": "917c72e2-470b-4cf1-c566-895f987779cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download and extraction complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and train AlexNet"
      ],
      "metadata": {
        "id": "B6jDIXVDlKq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the AlexNet architecture\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=200):  # Tiny ImageNet has 200 classes\n",
        "        super(AlexNet, self).__init__()\n",
        "        # Define the layers of AlexNet\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2)\n",
        "        self.pool1 = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 192, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool5 = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "        self.fc1 = nn.Linear(9216, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool5(F.relu(self.conv5(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "au--_36km_jN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rates = [0.1, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64]\n",
        "\n",
        "#Keep number of epochs low as i don't have enough computing power\n",
        "EPOCHS = 2\n",
        "\n",
        "# Define transforms for the input data\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize to a slightly larger square\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally\n",
        "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),  # Randomly jitter color\n",
        "    transforms.RandomRotation(10),  # Randomly rotate images within a 10 degree range\n",
        "    transforms.ToTensor(),  # Convert the image to a tensor\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize\n",
        "])\n",
        "\n",
        "# Load the Tiny ImageNet dataset\n",
        "# Note: You'll need to download the dataset and set the correct path.\n",
        "train_dataset = datasets.ImageFolder(root='/dataset/tiny-imagenet-200/train', transform=transform)\n",
        "val_dataset = datasets.ImageFolder(root='/dataset/tiny-imagenet-200/test', transform=transform)\n",
        "\n",
        "#define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "WXTDfCPvnBwo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = 10\n",
        "\n",
        "train_size = len(train_dataset) // ratio\n",
        "val_size = len(val_dataset) // ratio\n",
        "# Create a smaller subset by randomly sampling indices\n",
        "subset_indices_train = torch.randperm(len(train_dataset))[:train_size]\n",
        "subset_indices_val = torch.randperm(len(val_dataset))[:val_size]\n",
        "\n",
        "train_dataset = Subset(train_dataset, subset_indices_train)\n",
        "val_dataset = Subset(val_dataset, subset_indices_val)"
      ],
      "metadata": {
        "id": "2L_GLIRq3Jh_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Test the model\n",
        "tensor = torch.rand([1, 3, 224, 224]).to(device)\n",
        "\n",
        "model = AlexNet(num_classes=200).to(device)\n",
        "print(model)\n",
        "\n",
        "# Total parameters and trainable parameters.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")\n",
        "output = model(tensor)"
      ],
      "metadata": {
        "id": "hlEnOwie7xQK",
        "outputId": "40911cd8-177a-4db6-8e99-d57b4625d939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "  (fc2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "  (fc3): Linear(in_features=4096, out_features=200, bias=True)\n",
            ")\n",
            "57,823,240 total parameters.\n",
            "57,823,240 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs.to(device))\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(train_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "0cyuaw5UnWDy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in learning_rates:\n",
        "    #Set optimizer with given learning rate\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    for batch_size in batch_sizes:\n",
        "      print(f'BATCH SIZE: {batch_size} LEARNING RATE: {lr}')\n",
        "      #Set loaders with given batch size\n",
        "      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "      test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "      timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "      writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "      epoch_number = 0\n",
        "\n",
        "      best_vloss = 1_000_000.\n",
        "\n",
        "      for epoch in range(EPOCHS):\n",
        "          print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "          # Make sure gradient tracking is on, and do a pass over the data\n",
        "          model.train(True)\n",
        "          avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "          running_vloss = 0.0\n",
        "          # Set the model to evaluation mode, disabling dropout and using population\n",
        "          # statistics for batch normalization.\n",
        "          model.eval()\n",
        "\n",
        "          # Disable gradient computation and reduce memory consumption.\n",
        "          with torch.no_grad():\n",
        "              for i, vdata in enumerate(test_loader):\n",
        "                  vinputs, vlabels = vdata\n",
        "                  voutputs = model(vinputs.to(device))\n",
        "                  vloss = criterion(voutputs, vlabels.to(device))\n",
        "                  running_vloss += vloss\n",
        "\n",
        "          avg_vloss = running_vloss / (i + 1)\n",
        "          print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "          # Log the running loss averaged per batch\n",
        "          # for both training and validation\n",
        "          writer.add_scalars('Training vs. Validation Loss',\n",
        "                          { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                          epoch_number + 1)\n",
        "          writer.flush()\n",
        "\n",
        "          # Track best performance, and save the model's state\n",
        "          if avg_vloss < best_vloss:\n",
        "              best_vloss = avg_vloss\n",
        "              model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "              torch.save(model.state_dict(), model_path)\n",
        "\n",
        "          epoch_number += 1"
      ],
      "metadata": {
        "id": "t_hIAilM7hi8",
        "outputId": "b14be688-7422-483e-f439-f4a954bd5edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BATCH SIZE: 16 LEARNING RATE: 0.1\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298594066619873\n",
            "  batch 2000 loss: 5.2983174324035645\n",
            "  batch 3000 loss: 5.2983174324035645\n",
            "  batch 4000 loss: 5.2983174324035645\n",
            "  batch 5000 loss: 5.2983174324035645\n",
            "  batch 6000 loss: 5.2983174324035645\n",
            "LOSS train 5.2983174324035645 valid 5.298336029052734\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.2983174324035645\n",
            "  batch 2000 loss: 5.2983174324035645\n",
            "  batch 3000 loss: 5.2983174324035645\n",
            "  batch 4000 loss: 5.2983174324035645\n",
            "  batch 5000 loss: 5.2983174324035645\n",
            "  batch 6000 loss: 5.2983174324035645\n",
            "LOSS train 5.2983174324035645 valid 5.298336029052734\n",
            "BATCH SIZE: 32 LEARNING RATE: 0.1\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "  batch 2000 loss: 5.298318862915039\n",
            "  batch 3000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983317375183105\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "  batch 2000 loss: 5.298318862915039\n",
            "  batch 3000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983317375183105\n",
            "BATCH SIZE: 64 LEARNING RATE: 0.1\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983245849609375\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983245849609375\n",
            "BATCH SIZE: 16 LEARNING RATE: 0.001\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.2983174324035645\n",
            "  batch 2000 loss: 5.2983174324035645\n",
            "  batch 3000 loss: 5.2983174324035645\n",
            "  batch 4000 loss: 5.2983174324035645\n",
            "  batch 5000 loss: 5.2983174324035645\n",
            "  batch 6000 loss: 5.2983174324035645\n",
            "LOSS train 5.2983174324035645 valid 5.298336029052734\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.2983174324035645\n",
            "  batch 2000 loss: 5.2983174324035645\n",
            "  batch 3000 loss: 5.2983174324035645\n",
            "  batch 4000 loss: 5.2983174324035645\n",
            "  batch 5000 loss: 5.2983174324035645\n",
            "  batch 6000 loss: 5.2983174324035645\n",
            "LOSS train 5.2983174324035645 valid 5.298336029052734\n",
            "BATCH SIZE: 32 LEARNING RATE: 0.001\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "  batch 2000 loss: 5.298318862915039\n",
            "  batch 3000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983317375183105\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "  batch 2000 loss: 5.298318862915039\n",
            "  batch 3000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983317375183105\n",
            "BATCH SIZE: 64 LEARNING RATE: 0.001\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983245849609375\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983245849609375\n",
            "BATCH SIZE: 16 LEARNING RATE: 0.0001\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.2983174324035645\n",
            "  batch 2000 loss: 5.2983174324035645\n",
            "  batch 3000 loss: 5.2983174324035645\n",
            "  batch 4000 loss: 5.2983174324035645\n",
            "  batch 5000 loss: 5.2983174324035645\n",
            "  batch 6000 loss: 5.2983174324035645\n",
            "LOSS train 5.2983174324035645 valid 5.298336029052734\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.2983174324035645\n",
            "  batch 2000 loss: 5.2983174324035645\n",
            "  batch 3000 loss: 5.2983174324035645\n",
            "  batch 4000 loss: 5.2983174324035645\n",
            "  batch 5000 loss: 5.2983174324035645\n",
            "  batch 6000 loss: 5.2983174324035645\n",
            "LOSS train 5.2983174324035645 valid 5.298336029052734\n",
            "BATCH SIZE: 32 LEARNING RATE: 0.0001\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "  batch 2000 loss: 5.298318862915039\n",
            "  batch 3000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983317375183105\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "  batch 2000 loss: 5.298318862915039\n",
            "  batch 3000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983317375183105\n",
            "BATCH SIZE: 64 LEARNING RATE: 0.0001\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983245849609375\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 5.298318862915039\n",
            "LOSS train 5.298318862915039 valid 5.2983245849609375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and train ResNet"
      ],
      "metadata": {
        "id": "9pKWg6xOJO8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define basic block for ResNet\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        stride: int = 1,\n",
        "        expansion: int = 1,\n",
        "        downsample: nn.Module = None\n",
        "    ) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        # Multiplicative factor for the subsequent conv2d layer's output channels.\n",
        "        # It is 1 for ResNet18 and ResNet34.\n",
        "        self.expansion = expansion\n",
        "        self.downsample = downsample\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=stride,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            out_channels,\n",
        "            out_channels*self.expansion,\n",
        "            kernel_size=3,\n",
        "            padding=1,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels*self.expansion)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        identity = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return  out"
      ],
      "metadata": {
        "id": "3X7CqEGErpcS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_channels: int,\n",
        "        num_layers: int,\n",
        "        block: Type[BasicBlock],\n",
        "        num_classes: int  = 200\n",
        "    ) -> None:\n",
        "        super(ResNet, self).__init__()\n",
        "        if num_layers == 18:\n",
        "            # The following `layers` list defines the number of `BasicBlock`\n",
        "            # to use to build the network and how many basic blocks to stack\n",
        "            # together.\n",
        "            layers = [2, 2, 2, 2]\n",
        "            self.expansion = 1\n",
        "\n",
        "        self.in_channels = 64\n",
        "        # All ResNets (18 to 152) contain a Conv2d => BN => ReLU for the first\n",
        "        # three layers. Here, kernel size is 7.\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=img_channels,\n",
        "            out_channels=self.in_channels,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512*self.expansion, num_classes)\n",
        "    def _make_layer(\n",
        "        self,\n",
        "        block: Type[BasicBlock],\n",
        "        out_channels: int,\n",
        "        blocks: int,\n",
        "        stride: int = 1\n",
        "    ) -> nn.Sequential:\n",
        "        downsample = None\n",
        "        if stride != 1:\n",
        "            \"\"\"\n",
        "            This should pass from `layer2` to `layer4` or\n",
        "            when building ResNets50 and above. Section 3.3 of the paper\n",
        "            Deep Residual Learning for Image Recognition\n",
        "            (https://arxiv.org/pdf/1512.03385v1.pdf).\n",
        "            \"\"\"\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    self.in_channels,\n",
        "                    out_channels*self.expansion,\n",
        "                    kernel_size=1,\n",
        "                    stride=stride,\n",
        "                    bias=False\n",
        "                ),\n",
        "                nn.BatchNorm2d(out_channels * self.expansion),\n",
        "            )\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                self.in_channels, out_channels, stride, self.expansion, downsample\n",
        "            )\n",
        "        )\n",
        "        self.in_channels = out_channels * self.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(\n",
        "                self.in_channels,\n",
        "                out_channels,\n",
        "                expansion=self.expansion\n",
        "            ))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        # The spatial dimension of the final layer's feature\n",
        "        # map should be (7, 7) for all ResNets.\n",
        "        #print('Dimensions of the last convolutional feature map: ', x.shape)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "wZsxgWmTlW2R"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Test the model\n",
        "tensor = torch.rand([1, 3, 224, 224]).to(device)\n",
        "\n",
        "model = ResNet(img_channels=3, num_layers=18, block=BasicBlock, num_classes=200).to(device)\n",
        "print(model)\n",
        "\n",
        "# Total parameters and trainable parameters.\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"{total_params:,} total parameters.\")\n",
        "total_trainable_params = sum(\n",
        "    p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"{total_trainable_params:,} training parameters.\")\n",
        "output = model(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LML-dmxrrqv0",
        "outputId": "e86794a9-2f77-4bac-9b5f-7fb278664957"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=200, bias=True)\n",
            ")\n",
            "11,279,112 total parameters.\n",
            "11,279,112 training parameters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define hyperparameters\n",
        "EPOCHS = 2\n",
        "learning_rates = [0.1, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64]"
      ],
      "metadata": {
        "id": "DOUtR0ixt50D"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index, tb_writer):\n",
        "    running_loss = 0.\n",
        "    last_loss = 0.\n",
        "\n",
        "    # Here, we use enumerate(training_loader) instead of\n",
        "    # iter(training_loader) so that we can track the batch\n",
        "    # index and do some intra-epoch reporting\n",
        "    for i, data in enumerate(train_loader):\n",
        "        # Every data instance is an input + label pair\n",
        "        inputs, labels = data\n",
        "\n",
        "        # Zero your gradients for every batch!\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Make predictions for this batch\n",
        "        outputs = model(inputs.to(device))\n",
        "\n",
        "        # Compute the loss and its gradients\n",
        "        loss = criterion(outputs, labels.to(device))\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Gather data and report\n",
        "        running_loss += loss.item()\n",
        "        if i % 1000 == 999:\n",
        "            last_loss = running_loss / 1000 # loss per batch\n",
        "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
        "            tb_x = epoch_index * len(train_loader) + i + 1\n",
        "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
        "            running_loss = 0.\n",
        "\n",
        "    return last_loss"
      ],
      "metadata": {
        "id": "U_h1UZbFslT9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for lr in learning_rates:\n",
        "    #Set optimizer with given learning rate\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "    print(f'LEARNING RATE: {lr}')\n",
        "    for batch_size in batch_sizes:\n",
        "      print(f'BATCH SIZE: {batch_size}')\n",
        "      #Set loaders with given batch size\n",
        "      train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "      test_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "      timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "      writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
        "      epoch_number = 0\n",
        "\n",
        "      best_vloss = 1_000_000.\n",
        "\n",
        "      for epoch in range(EPOCHS):\n",
        "          print('EPOCH {}:'.format(epoch_number + 1))\n",
        "\n",
        "          # Make sure gradient tracking is on, and do a pass over the data\n",
        "          model.train(True)\n",
        "          avg_loss = train_one_epoch(epoch_number, writer)\n",
        "\n",
        "\n",
        "          running_vloss = 0.0\n",
        "          # Set the model to evaluation mode, disabling dropout and using population\n",
        "          # statistics for batch normalization.\n",
        "          model.eval()\n",
        "\n",
        "          # Disable gradient computation and reduce memory consumption.\n",
        "          with torch.no_grad():\n",
        "              for i, vdata in enumerate(test_loader):\n",
        "                  vinputs, vlabels = vdata\n",
        "                  voutputs = model(vinputs.to(device))\n",
        "                  vloss = criterion(voutputs, vlabels.to(device))\n",
        "                  running_vloss += vloss\n",
        "\n",
        "          avg_vloss = running_vloss / (i + 1)\n",
        "          print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "\n",
        "          # Log the running loss averaged per batch\n",
        "          # for both training and validation\n",
        "          writer.add_scalars('Training vs. Validation Loss',\n",
        "                          { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                          epoch_number + 1)\n",
        "          writer.flush()\n",
        "\n",
        "          # Track best performance, and save the model's state\n",
        "          if avg_vloss < best_vloss:\n",
        "              best_vloss = avg_vloss\n",
        "              model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
        "              torch.save(model.state_dict(), model_path)\n",
        "\n",
        "          epoch_number += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPCWOKaI0PFs",
        "outputId": "7e889723-e3b9-4d65-9141-5dff472421b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LEARNING RATE: 0.1\n",
            "BATCH SIZE: 16\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 5.3399882373809815\n",
            "  batch 2000 loss: 5.186742506027222\n",
            "  batch 3000 loss: 5.085517208576203\n",
            "  batch 4000 loss: 4.9906835675239565\n",
            "  batch 5000 loss: 4.8511982479095455\n",
            "  batch 6000 loss: 4.770976055860519\n",
            "LOSS train 4.770976055860519 valid 6.9782304763793945\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 4.6696875741481785\n",
            "  batch 2000 loss: 4.564825007438659\n",
            "  batch 3000 loss: 4.512168281078338\n",
            "  batch 4000 loss: 4.466344439029694\n",
            "  batch 5000 loss: 4.392468120574951\n",
            "  batch 6000 loss: 4.344879398822784\n",
            "LOSS train 4.344879398822784 valid 6.855801582336426\n",
            "BATCH SIZE: 32\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 3.995617347240448\n",
            "  batch 2000 loss: 3.910241993188858\n",
            "  batch 3000 loss: 3.8595100293159486\n",
            "LOSS train 3.8595100293159486 valid 7.487232685089111\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 3.7645210614204405\n",
            "  batch 2000 loss: 3.7261436128616334\n",
            "  batch 3000 loss: 3.6837412023544314\n",
            "LOSS train 3.6837412023544314 valid 7.159038543701172\n",
            "BATCH SIZE: 64\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 3.261654366493225\n",
            "LOSS train 3.261654366493225 valid 7.485018253326416\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 3.134442121267319\n",
            "LOSS train 3.134442121267319 valid 8.282119750976562\n",
            "LEARNING RATE: 0.001\n",
            "BATCH SIZE: 16\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.923960999727249\n",
            "  batch 2000 loss: 2.7683379682302474\n",
            "  batch 3000 loss: 2.730803519487381\n",
            "  batch 4000 loss: 2.6569544612169267\n",
            "  batch 5000 loss: 2.6387920801639555\n",
            "  batch 6000 loss: 2.6215066521167754\n",
            "LOSS train 2.6215066521167754 valid 10.309918403625488\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 2.598763456106186\n",
            "  batch 2000 loss: 2.554713419675827\n",
            "  batch 3000 loss: 2.5376245081424713\n",
            "  batch 4000 loss: 2.520815112352371\n",
            "  batch 5000 loss: 2.4968161877393724\n",
            "  batch 6000 loss: 2.469017390370369\n",
            "LOSS train 2.469017390370369 valid 10.705968856811523\n",
            "BATCH SIZE: 32\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.3086293666362763\n",
            "  batch 2000 loss: 2.310172463774681\n",
            "  batch 3000 loss: 2.300648088097572\n",
            "LOSS train 2.300648088097572 valid 10.416668891906738\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 2.258357393145561\n",
            "  batch 2000 loss: 2.2664542863368986\n",
            "  batch 3000 loss: 2.248272349476814\n",
            "LOSS train 2.248272349476814 valid 10.649800300598145\n",
            "BATCH SIZE: 64\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.150488889217377\n",
            "LOSS train 2.150488889217377 valid 10.565190315246582\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 2.1129923025369646\n",
            "LOSS train 2.1129923025369646 valid 10.626362800598145\n",
            "LEARNING RATE: 0.0001\n",
            "BATCH SIZE: 16\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.266537828207016\n",
            "  batch 2000 loss: 2.282622031331062\n",
            "  batch 3000 loss: 2.2803419798612596\n",
            "  batch 4000 loss: 2.2667178514003754\n",
            "  batch 5000 loss: 2.2655579956769945\n",
            "  batch 6000 loss: 2.293010744690895\n",
            "LOSS train 2.293010744690895 valid 10.922364234924316\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 2.2573023191690447\n",
            "  batch 2000 loss: 2.2574842311143875\n",
            "  batch 3000 loss: 2.249630677342415\n",
            "  batch 4000 loss: 2.2733105533123017\n",
            "  batch 5000 loss: 2.274581857919693\n",
            "  batch 6000 loss: 2.2624979004859926\n",
            "LOSS train 2.2624979004859926 valid 10.91413688659668\n",
            "BATCH SIZE: 32\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.1208346269130707\n",
            "  batch 2000 loss: 2.132926861286163\n",
            "  batch 3000 loss: 2.1151702864170074\n",
            "LOSS train 2.1151702864170074 valid 10.564732551574707\n",
            "EPOCH 2:\n",
            "  batch 1000 loss: 2.118762209892273\n",
            "  batch 2000 loss: 2.114936947822571\n",
            "  batch 3000 loss: 2.109163765192032\n",
            "LOSS train 2.109163765192032 valid 10.598255157470703\n",
            "BATCH SIZE: 64\n",
            "EPOCH 1:\n",
            "  batch 1000 loss: 2.0401814185380935\n",
            "LOSS train 2.0401814185380935 valid 10.465173721313477\n",
            "EPOCH 2:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because of lack of computing power we have only used 2 epochs, this leads to high losses and not accurate results for a real world test. However we can deduce that some hyperparameters had better results for the epochs and batches than others ie. they converged faster. We also had problems with convergence on the AlexNet not converging, this could possibly be solved by altering the optimizer parameters for instance the weight decay."
      ],
      "metadata": {
        "id": "FZQ4SqRS_Js5"
      }
    }
  ]
}