{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LG0oHy248_T4D0Orr-_c8s1beimZwXYv","timestamp":1711473312678},{"file_id":"1o_FDDuxpBegMshyuHsRowz42dX43WwRD","timestamp":1710846153016}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### PyTorch CustomNet Exercises\n","\n","Welcome to the PyTorch CustomNet exercise template notebook.\n","\n","There are several questions in this notebook and it's your goal to answer them by writing Python and PyTorch code.\n","\n","> **Note:** There may be more than one solution to each of the exercises, don't worry too much about the *exact* right answer. Try to write some code that works first and then improve it if you can."],"metadata":{"id":"krpPSRxDQFiJ"}},{"cell_type":"code","source":["# Import necessary libraries\n","import os\n","import requests\n","from zipfile import ZipFile\n","from io import BytesIO\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","import torch.nn.functional as F"],"metadata":{"id":"cawD5z5DaBLl","executionInfo":{"status":"ok","timestamp":1712168044537,"user_tz":-120,"elapsed":11629,"user":{"displayName":"Johan Lindell","userId":"12886028082128920167"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Define the path to the dataset\n","dataset_path = 'http://cs231n.stanford.edu/tiny-imagenet-200.zip'  # Replace with the path to your dataset\n","\n","# Send a GET request to the URL\n","response = requests.get(dataset_path)\n","# Check if the request was successful\n","if response.status_code == 200:\n","    # Open the downloaded bytes and extract them\n","    with ZipFile(BytesIO(response.content)) as zip_file:\n","        zip_file.extractall('/dataset')\n","    print('Download and extraction complete!')"],"metadata":{"id":"04f83M7mZ6u2","executionInfo":{"status":"ok","timestamp":1712168111674,"user_tz":-120,"elapsed":67141,"user":{"displayName":"Johan Lindell","userId":"12886028082128920167"}},"outputId":"1592d8d6-0f87-42ae-fe97-e01e7f5d53e2","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Download and extraction complete!\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"id":"G0i-tDmhO_41","outputId":"a22a6e66-d1fc-48e8-9c39-b3473f7442db","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1712173272701,"user_tz":-120,"elapsed":641132,"user":{"displayName":"Johan Lindell","userId":"12886028082128920167"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 Loss: 5.266485 Acc: 0.94%\n","Train Epoch: 2 Loss: 4.996660 Acc: 2.70%\n","Train Epoch: 3 Loss: 4.826947 Acc: 4.67%\n","Train Epoch: 4 Loss: 4.640512 Acc: 6.73%\n","Train Epoch: 5 Loss: 4.496919 Acc: 8.36%\n","Train Epoch: 6 Loss: 4.383195 Acc: 9.86%\n","Train Epoch: 7 Loss: 4.276799 Acc: 11.37%\n","Train Epoch: 8 Loss: 4.176665 Acc: 12.61%\n","Train Epoch: 9 Loss: 4.083001 Acc: 13.97%\n","Train Epoch: 10 Loss: 3.985425 Acc: 15.39%\n","Test Loss: 8.233466 Acc: 0.63%\n"]}],"source":["# Define the custom neural network\n","class CustomNet(nn.Module):\n","    def __init__(self):\n","        super(CustomNet, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n","        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n","        self.fc2 = nn.Linear(512, 512)\n","        self.fc3 = nn.Linear(512, 200)\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","\n","    def forward(self, x):\n","      x = self.pool(F.relu(self.conv1(x)))\n","      x = F.dropout(x, p=0.5)\n","      x = self.pool(F.relu(self.conv2(x)))\n","      x = torch.flatten(x, 1)\n","      x = F.relu(self.fc1(x))\n","      x = F.relu(self.fc2(x))\n","      x = self.fc3(x)\n","      return x\n","\n","# Define transforms\n","transform = transforms.Compose([\n","    transforms.Resize((32, 32)),  # Resize to fit the input dimensions of the network\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","\n","# Load TinyImageNet\n","train_dataset = datasets.ImageFolder(root='/dataset/tiny-imagenet-200/train', transform=transform)\n","test_dataset = datasets.ImageFolder(root='/dataset/tiny-imagenet-200/test', transform=transform)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","# Initialize the model\n","model = CustomNet().cuda()\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n","\n","# Training loop\n","def train(epoch, model, train_loader, criterion, optimizer):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for batch_idx, (inputs, targets) in enumerate(train_loader):\n","        inputs, targets = inputs.cuda(), targets.cuda()\n","        outputs = model(inputs)\n","        optimizer.zero_grad()\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","    train_loss = running_loss / len(train_loader)\n","    train_accuracy = 100. * correct / total\n","    print(f'Train Epoch: {epoch} Loss: {train_loss:.6f} Acc: {train_accuracy:.2f}%')\n","\n","# Test loop\n","def test(model, test_loader, criterion):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(test_loader):\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","    test_loss = test_loss / len(test_loader)\n","    test_accuracy = 100. * correct / total\n","    print(f'Test Loss: {test_loss:.6f} Acc: {test_accuracy:.2f}%')\n","    return test_accuracy\n","\n","# Run the training and testing\n","num_epochs = 10\n","for epoch in range(1, num_epochs + 1):\n","    train(epoch, model, train_loader, criterion, optimizer)\n","test_accuracy = test(model, test_loader, criterion)"]}]}